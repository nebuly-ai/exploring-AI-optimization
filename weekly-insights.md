<p align="center">
  <a href="https://www.nebuly.com/towards-efficient-ai">Subscribe to the newsletter</a> •
  <a href="https://discord.gg/RbeQMu886J">Join the community</a>
</p>

<img height="25" width="100%" src="https://user-images.githubusercontent.com/83510798/211585773-c7610d6f-634c-4ba7-957c-72c3fb5af999.png">


# Weekly insights from top papers on AI

Welcome to our library of the best insights from the best papers on AI and machine learning. A new paper will be added every Friday. <br />
Don't hesitate to [open an issue](https://github.com/nebuly-ai/exploring-AI-optimization/issues) and submit a paper that you found interesting and the 3 key takeaways. 

## Week #5: [Multimodal Chain-of-Thought Reasoning in Language Models](https://arxiv.org/pdf/2302.00923v2.pdf)

- The paper introduces Multimodal-CoT, a framework for incorporating vision signals in chain-of-thought (CoT) reasoning with 1B-models. The framework decouples rationale generation and answer inference into two stages, and incorporates vision features to help generate more effective rationales for more accurate answer inference.
- The authors compare Multimodal-CoT with GPT-3.5 on the ScienceQA benchmark and show that their approach surpasses GPT-3.5 by 16% accuracy. They also show that different vision features and backbone models affect the performance of the model, and that DETR (based on object detection) is the best performing vision feature.
- The authors perform a manual error analysis on randomly selected examples generated by Multimodal-CoT. They find that the majority of the errors are due to factual mistakes (failures in understanding maps and counting numbers in the images), commonsense mistakes (answering questions that require commonsense knowledge), and logical mistakes (contradictions in the reasoning chains).


## Week #6: [Adding Conditional Control to Text-to-Image Diffusion Models](https://arxiv.org/pdf/2302.05543.pdf)

- The paper presents a neural network architecture called ControlNet that can control large image diffusion models (like Stable Diffusion) to learn task-specific input conditions.
- The ControlNet consists of a "trainable copy" and a "locked copy" of a large diffusion model, connected by a unique type of convolution layer called "zero convolution", which allows for end-to-end learning while preserving the generalization ability of the original model.
- ControlNet can be trained on small datasets (even <1k samples) and on personal devices, and can still achieve competitive results with models trained on large computation clusters with terabytes of GPU memory and thousands of GPU hours.

## Week #4: [MusicLM: Generating Music From Text](https://arxiv.org/pdf/2301.11325.pdf)

- MusicLM is a text-conditioned generative model that can produce high-quality music. The model is trained on a synthetic dataset of audio pairs with matching melodies and different acoustics, as well as data pairs of people humming and singing. The text description is used as a conditioning signal to guide the music generation process.
- The model is able to generate music that follows the target melody contained in the input audio clip, while also being faithful to the text description. MusicLM is capable of generating long, coherent audio sequences that are semantically plausible and consistent with the text description. The model can also be used in "story mode," where the text description changes over time, leading to smooth transitions in the generated music.
- There are several risks associated with MusicLM and its use-case, such as the reflection of biases present in the training data and the potential misappropriation of creative content. The authors conducted a thorough study of memorization and found that only a small fraction of examples was memorized exactly.


## Week #3: [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/pdf/2201.11903.pdf)

- The ability of a Large Language Model (LLM) to produce a better quality response is closely related to the prompt used. For example, providing the model with an example or a chain of thoughts (CoT) as a prompt produces a higher quality response without training; this type of technique is usually called InContextLearning, since the model learns from the provided context instead of updating parameters.
- The chain-of-thought prompt is particularly useful in arithmetic reasoning, and it has been shown that for symbolic reasoning, the chain-of-thought prompt facilitates generalization of the out-of-distribution to longer sequences.
- A comparative analysis of the usefulness of chain reasoning versus model size was conducted, showing that larger models are better reasoners and can benefit more from the chain reasoning prompt than smaller models.


## Week #2: [Explanations from Large Language Models Make Small Reasoners Better](https://arxiv.org/pdf/2210.06726.pdf)

- Tuning and inference of LLMs are not trivial in terms of computational cost, so creating smaller models that can be used to solve specific tasks using LLMs as teachers can have several advantages.
- In this case, an LLM is used to produce chain reasoning that is then validated by comparing the final what answer from the LLM with that provided by dataset y. A new dataset {x, e, y} of explanations is then created from a smaller dataset {x, y} containing only question and answer; the new dataset of examples is used to train a smaller T5 3B model to produce the answer along with the chain of thought.
- The results show that the resulting model has comparable performance on the Common Sense Question Answering dataset of GPT3 using Zero-Shot-CoT.


## Week #1: [Holistic Evaluation of Language Models (HELM)](https://arxiv.org/pdf/2211.09110.pdf)

- The Holistic Evaluation of Language Models (HELM) is a toolkit designed to improve the transparency of language models and better understand their capabilities, limitations, and risks.
- HELM uses a multi-metric approach to evaluate language models across a wide range of scenarios and metrics, including accuracy, calibration, robustness, fairness, bias, toxicity, and efficiency.
- HELM conducts a large-scale evaluation of 30 prominent language models across 42 different scenarios, including 21 that have not previously been used in mainstream LM evaluation. The results of the evaluation and all raw model prompts and completions are made publicly available.


<img height="25" width="100%" src="https://user-images.githubusercontent.com/83510798/211585773-c7610d6f-634c-4ba7-957c-72c3fb5af999.png">

<p align="center">
  <a href="https://www.nebuly.com/towards-efficient-ai">Subscribe to the newsletter</a> •
  <a href="https://discord.gg/RbeQMu886J">Join the community</a>
</p>
