<p align="center">
  <a href="https://discord.gg/RbeQMu886J">Subscribe to the newsletter</a> •
  <a href="https://discord.gg/RbeQMu886J">Join the community</a> •
  <a href="#contribute">Contribute to the library</a>
</p>

<img height="25" width="100%" src="https://user-images.githubusercontent.com/83510798/182182529-f86afbf2-db16-434d-b907-a80838ffebd2.png">


# Weekly insights from top papers on AI

Welcome to our library of the best insights from the best papers on AI and machine learning. A new paper will be added every Friday. <br />
Don't hesitate to [open an issue](https://github.com/nebuly-ai/exploring-AI-optimization/issues) and submit a paper that you found interesting and the 3 key takeaways. 


## Week #1: [Holistic Evaluation of Language Models (HELM)](https://arxiv.org/pdf/2211.09110.pdf)

- The Holistic Evaluation of Language Models (HELM) is a toolkit designed to improve the transparency of language models and better understand their capabilities, limitations, and risks.
- HELM uses a multi-metric approach to evaluate language models across a wide range of scenarios and metrics, including accuracy, calibration, robustness, fairness, bias, toxicity, and efficiency.
- HELM conducts a large-scale evaluation of 30 prominent language models across 42 different scenarios, including 21 that have not previously been used in mainstream LM evaluation. The results of the evaluation and all raw model prompts and completions are made publicly available.



<img height="25" width="100%" src="https://user-images.githubusercontent.com/83510798/182182529-f86afbf2-db16-434d-b907-a80838ffebd2.png">


<p align="center">
  <a href="https://discord.gg/RbeQMu886J">Subscribe to the newsletter</a> •
  <a href="https://discord.gg/RbeQMu886J">Join the community</a> •
  <a href="#contribute">Contribute to the library</a>
</p>
